{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "psychological-nelson",
   "metadata": {},
   "source": [
    "# Práctica 3b: Caracterización y Clasificación de Texturas\n",
    "## Gabriel Daniel Aguilar Luna, Zuriel Uzai Rodrígez Agiss\n",
    "### _Facultad de Ingenierría, Universidad Nacional Autónoma de México_\n",
    "### _Ciudad de México, México_\n",
    "#### gabriel.aguilar@ingenieria.unam.edu,  zurieluzai2015@gmail.com\n",
    "\n",
    "***\n",
    "\n",
    "### __1. Objetivos__\n",
    "\n",
    "El alumno:\n",
    "- Desarrollará métodos de caracterización de texturas\n",
    "- Aprenderáa utilizar clasificadores como K-NN,K-Means omáquinas de soporte vectoria\n",
    "\n",
    "***\n",
    "\n",
    "### __3. Desarrollo__\n",
    "\n",
    "##### Imports y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "objective-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage as ski\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from descartes import PolygonPatch\n",
    "from math import log\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "# Esta funcion 'desdobla' cadenas para crear un rango y un numero\n",
    "# eg: '100'=mayores que 100, '0-50'= entre 0 y 50, '10-20,500'= entre 10 y 20 o mayores de 500\n",
    "def listRanger(rango: str):\n",
    "    # Separa la cadena por comas\n",
    "    rango = rango.split(',')\n",
    "    # Definicion de las variables de retorno\n",
    "    listarango = []\n",
    "    mayorq = -1\n",
    "    # Recorre las sentencias separadas anteriormente\n",
    "    for x in rango:\n",
    "        # Si la sentencia tiene un '-' es un rango\n",
    "        if '-' in x:\n",
    "            # Los rangos se añaden a la lista listarango\n",
    "            listax = x.split('-')\n",
    "            listarango += list(range(int(listax[0]),int(listax[1])))\n",
    "        # Si no, es una cota inferior\n",
    "        else:\n",
    "            # Solo puede existir una de estas cotas en la sentencia\n",
    "            mayorq = int(x)\n",
    "\n",
    "    return [listarango, mayorq]\n",
    "\n",
    "# Esta función imprime la imagen junto con las curvas de la posición nColl de contornos\n",
    "# Que cumplan con range y retorna un arreglo con dichas curvas.\n",
    "# Se puede especificar los puntos en el perimetro de las lineas con range. eg: range='400-560'\n",
    "# Si no se especifica se utiliza '150'\n",
    "# Se puede especificar un nombre para guardar la imagen resultante con save. eg: save='imagen2.png'\n",
    "# Si no se especifica se utiliza 'ImCrTMP.png'\n",
    "# eg: masker.printImCr(fruta, fruta_contornos, 1, range='200', save='comida_contornos.png')\n",
    "def printImCr(imagen, contornos, nColl, **kwargs):\n",
    "    # Desdobla range\n",
    "    rangolstd = listRanger(kwargs[\"range\"] if (\"range\" in kwargs) else '150')\n",
    "    # Define variable de retorno\n",
    "    curvas_array = []\n",
    "    # Con este for se muestran todas las lineas cuya primera dimension entre en el rango\n",
    "    for i in contornos.collections[nColl].get_paths():\n",
    "        # Si cumple con las caracteristicas indicadas en range se añade al plot y a la var de retorno\n",
    "        if len(i.vertices) in rangolstd[0] or ((len(i.vertices) > rangolstd[1]) if (rangolstd[1] != -1) else (len(i.vertices) > len(i.vertices)+1)):\n",
    "            plt.plot(i.vertices[:,0], i.vertices[:,1], '--b')\n",
    "            curvas_array.append(i.vertices)\n",
    "    # Muestra la imagen\n",
    "    plt.imshow(imagen)\n",
    "    plt.axis('off')\n",
    "    # Salva la imagen\n",
    "    plt.savefig('resultados/'+kwargs[\"save\"] if (\"save\" in kwargs) else 'resultados/ImCrTMP.png', bbox_inches='tight', transparent=False, pad_inches = 0)\n",
    "    # Regresa el arreglo\n",
    "    return curvas_array\n",
    "\n",
    "# Esta función imprime la imagen de fondo junto con los poligonos\n",
    "# Definidos por las curvas en curvas_arr\n",
    "# Retorna un obj Multipolygon\n",
    "def printImPoly(curvas_arr, fondo):\n",
    "    # Arreglo aux\n",
    "    poly_array = []\n",
    "    # Recorre arreglo de curvas\n",
    "    for crvua in curvas_arr:\n",
    "        x = crvua[:,0]\n",
    "        y = crvua[:,1]\n",
    "        poly_array.append(Polygon([(i[0], i[1]) for i in zip(x,y)]))\n",
    "    polygons = MultiPolygon(poly_array)\n",
    "    #len(polygons.geoms)\n",
    "    #polygons\n",
    "    fig = plt.figure() \n",
    "    ax = fig.gca()\n",
    "\n",
    "    # Plotea la imagen de fondo\n",
    "    plt.imshow(fondo)\n",
    "    # Plotea los poligonos\n",
    "    for poly in polygons:\n",
    "        ax.add_patch(PolygonPatch(poly))\n",
    "    #ax.axis('scaled')\n",
    "    plt.show()\n",
    "    # Retorna los poligonos\n",
    "    return polygons\n",
    "\n",
    "# Calcula el valor SIGMA de una matriz\n",
    "def getSigma(matriz_pix):\n",
    "    MU = np.mean(matriz_pix, axis=0)\n",
    "    SIGMA = np.zeros((len(MU),len(MU)))\n",
    "\n",
    "    for pixel in matriz_pix:\n",
    "        P_MU = np.array([pixel-MU])\n",
    "        SIGMA += np.dot(np.transpose(P_MU),P_MU)\n",
    "    \n",
    "    return SIGMA / len(matriz_pix)\n",
    "\n",
    "# Calcula la probabilidad de una clase\n",
    "def probaClase(lenClase, x, y, n):\n",
    "    return lenClase/(x*y*n)\n",
    "\n",
    "# Calcula la parte derecha de la clasificación\n",
    "def ladoDerecho(SIGMA_det, probaClase):\n",
    "    return (-log(SIGMA_det)/2) + log(probaClase)\n",
    "\n",
    "# Calcula la probabilidad de que un pixel pertenezca a una clase\n",
    "def probaPixClase(pixel, MU, SIGMA_inv):\n",
    "    P_MU = np.array([pixel-MU])\n",
    "    #print((np.dot(np.dot(P_MU,SIGMA_inv), np.transpose(P_MU))[0,0])/-2)\n",
    "    return (np.dot(np.dot(P_MU,SIGMA_inv), np.transpose(P_MU))[0,0])/-2\n",
    "\n",
    "# Clasifica los pixeles de una imagen en las clases dadas.\n",
    "def clasificador(imagen, MUs, SIGMAs_inv, ldDers, colores, **kwargs):\n",
    "    show = (kwargs[\"show\"] if (\"show\" in kwargs) else False)\n",
    "    if (isinstance(imagen, str)):\n",
    "        prueba_img = io.imread(imagen)\n",
    "        prueba = np.array(prueba_img)\n",
    "    elif(isinstance(imagen, np.ndarray)):\n",
    "        prueba = imagen\n",
    "    if show:    \n",
    "        plt.imshow(prueba)\n",
    "        plt.show()\n",
    "    \n",
    "    dimensiones = prueba.shape\n",
    "    resultado = np.zeros((dimensiones[0],dimensiones[1],3), dtype=int)\n",
    "    for i in range(len(prueba)):\n",
    "        for j in range(len(prueba[i])):\n",
    "            arr_aux = []\n",
    "            for n in range(len(MUs)):\n",
    "                arr_aux.append(probaPixClase(prueba[i][j], MUs[n], SIGMAs_inv[n])+ldDers[n])\n",
    "            resultado[i][j]= colores[arr_aux.index(max(arr_aux))]\n",
    "    return resultado\n",
    "\n",
    "# Lista de texturas a utilizar.\n",
    "def listaTexturas(text_names):\n",
    "    texturas_array = []\n",
    "    for text_name in text_names:\n",
    "        objeto = io.imread('texturas/D'+text_name+'.bmp')\n",
    "        texturas_array.append(np.array(objeto)[:,:,0])\n",
    "        plt.imshow(objeto)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return texturas_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-exposure",
   "metadata": {},
   "source": [
    "### Funciones de obtención de matrices GLCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proved-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLCM horizaontal\n",
    "def glcmMaker_h(ventana, norm = False): \n",
    "    matriz_auxiliar = np.zeros((np.amax(ventana)+1,)*2, dtype=int)\n",
    "    Y, X = ventana.shape\n",
    "    normalizador = 0\n",
    "    for renglon in ventana:\n",
    "        for j in range(X-1):\n",
    "            matriz_auxiliar[renglon[j]][renglon[j+1]] += 1\n",
    "            normalizador += 2\n",
    "    glcm = matriz_auxiliar + np.transpose(matriz_auxiliar)\n",
    "    return (glcm/normalizador) if norm else glcm\n",
    "\n",
    "# GLCM vertical\n",
    "def glcmMaker_v(ventana, norm = False): \n",
    "    matriz_auxiliar = np.zeros((np.amax(ventana)+1,)*2, dtype=int)\n",
    "    Y, X = ventana.shape\n",
    "    normalizador = 0\n",
    "    for i in range(Y-1):\n",
    "        for j in range(X):\n",
    "            matriz_auxiliar[ventana[i][j]][ventana[i+1][j]] += 1\n",
    "            normalizador += 2\n",
    "    glcm = matriz_auxiliar + np.transpose(matriz_auxiliar)\n",
    "    return (glcm/normalizador) if norm else glcm\n",
    "\n",
    "# GLCM diagonal (esq.inf.izq -> esq.sup.der.)\n",
    "def glcmMaker_45(ventana, norm = False): \n",
    "    matriz_auxiliar = np.zeros((np.amax(ventana)+1,)*2, dtype=int)\n",
    "    Y, X = ventana.shape\n",
    "    normalizador = 0\n",
    "    for i in range(1,Y):\n",
    "        for j in range(X-1):\n",
    "            matriz_auxiliar[ventana[i][j]][ventana[i-1][j+1]] += 1\n",
    "            normalizador += 2\n",
    "    glcm = matriz_auxiliar + np.transpose(matriz_auxiliar)\n",
    "    return (glcm/normalizador) if norm else glcm\n",
    "\n",
    "# GLCM diagonal (esq.sup.izq. -> esq.inf.der.)\n",
    "def glcmMaker_135(ventana, norm = False): \n",
    "    matriz_auxiliar = np.zeros((np.amax(ventana)+1,)*2, dtype=int)\n",
    "    Y, X = ventana.shape\n",
    "    normalizador = 0\n",
    "    for i in range(1,Y):\n",
    "        for j in range(1,X):\n",
    "            matriz_auxiliar[ventana[i][j]][ventana[i-1][j-1]] += 1\n",
    "            normalizador += 2\n",
    "    glcm = matriz_auxiliar + np.transpose(matriz_auxiliar)\n",
    "    return (glcm/normalizador) if norm else glcm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-dealer",
   "metadata": {},
   "source": [
    "### Funciones de obtención de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "demographic-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(glcm_n):\n",
    "    entropia = 0\n",
    "    for renglon in glcm_n:\n",
    "        for value in renglon:\n",
    "            entropia += (value*log(value)) if (value>0) else 0\n",
    "    return -entropia\n",
    "\n",
    "def homogeneity(glcm_n):\n",
    "    homogeneidad = 0\n",
    "    Y, X = glcm_n.shape\n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            homogeneidad += glcm_n[i][j]/(1+abs(i-j))\n",
    "    return homogeneidad\n",
    "\n",
    "#Angular Second Moment, Energy\n",
    "def smoothness(glcm_n):\n",
    "    ASM = 0\n",
    "    Y, X = glcm_n.shape\n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            ASM += glcm_n[i][j]**2\n",
    "    return ASM\n",
    "\n",
    "def contrast(glcm_n,k=2,n=1):\n",
    "    contraste = 0\n",
    "    Y, X = glcm_n.shape\n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            contraste += ((i-j)**k)*(glcm_n[i][j]**n)\n",
    "    return contraste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "previous-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recibe una imagen y un tamaño de ventana,\n",
    "# Calcula la entropia para cada ventana de la imagen\n",
    "# Regresa un arreglo en forma de imagen concatenando los resultados de cada ventana.\n",
    "def imagenWEntropy(imagen,window_length,window_height,**kwargs):\n",
    "    Y, X = imagen.shape\n",
    "    array_aux = []\n",
    "    length_overlap = (kwargs[\"length_overlap\"] if (\"length_overlap\" in kwargs) else 0)\n",
    "    height_overlap = (kwargs[\"height_overlap\"] if (\"height_overlap\" in kwargs) else 0)\n",
    "    mostrar = (kwargs[\"show\"] if (\"show\" in kwargs) else False)\n",
    "    for texel_renglon in range(0,Y,window_height-height_overlap):\n",
    "        renglon_aux = []\n",
    "        for texel_startP in range(0,X,window_length-length_overlap):\n",
    "            ventana = imagen[texel_renglon:texel_renglon+window_height,texel_startP:texel_startP+window_length]\n",
    "            glcm_N = glcmMaker_h(ventana,True)\n",
    "            renglon_aux.append(entropy(glcm_N))\n",
    "        array_aux.append(renglon_aux)\n",
    "    imagen_res = np.array(array_aux)\n",
    "    if mostrar:\n",
    "        plt.imshow(imagen_res)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return imagen_res\n",
    "\n",
    "# Recibe una imagen y un tamaño de ventana,\n",
    "# Calcula la homogeneidad para cada ventana de la imagen\n",
    "# Regresa un arreglo en forma de imagen concatenando los resultados de cada ventana.\n",
    "def imagenWHomogeneity(imagen,window_length,window_height,**kwargs):\n",
    "    Y, X = imagen.shape\n",
    "    array_aux = []\n",
    "    length_overlap = (kwargs[\"length_overlap\"] if (\"length_overlap\" in kwargs) else 0)\n",
    "    height_overlap = (kwargs[\"height_overlap\"] if (\"height_overlap\" in kwargs) else 0)\n",
    "    mostrar = (kwargs[\"show\"] if (\"show\" in kwargs) else False)\n",
    "    for texel_renglon in range(0,Y,window_height-height_overlap):\n",
    "        renglon_aux = []\n",
    "        for texel_startP in range(0,X,window_length-length_overlap):\n",
    "            ventana = imagen[texel_renglon:texel_renglon+window_height,texel_startP:texel_startP+window_length]\n",
    "            glcm_N = glcmMaker_h(ventana,True)\n",
    "            renglon_aux.append(homogeneity(glcm_N))\n",
    "        array_aux.append(renglon_aux)\n",
    "    imagen_res = np.array(array_aux)\n",
    "    if mostrar:\n",
    "        plt.imshow(imagen_res)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return imagen_res\n",
    "\n",
    "# Recibe una imagen y un tamaño de ventana,\n",
    "# Calcula la energia para cada ventana de la imagen\n",
    "# Regresa un arreglo en forma de imagen concatenando los resultados de cada ventana.\n",
    "def imagenWSmoothness(imagen,window_length,window_height,**kwargs):\n",
    "    Y, X = imagen.shape\n",
    "    array_aux = []\n",
    "    length_overlap = (kwargs[\"length_overlap\"] if (\"length_overlap\" in kwargs) else 0)\n",
    "    height_overlap = (kwargs[\"height_overlap\"] if (\"height_overlap\" in kwargs) else 0)\n",
    "    mostrar = (kwargs[\"show\"] if (\"show\" in kwargs) else False)\n",
    "    for texel_renglon in range(0,Y,window_height-height_overlap):\n",
    "        renglon_aux = []\n",
    "        for texel_startP in range(0,X,window_length-length_overlap):\n",
    "            ventana = imagen[texel_renglon:texel_renglon+window_height,texel_startP:texel_startP+window_length]\n",
    "            glcm_N = glcmMaker_h(ventana,True)\n",
    "            renglon_aux.append(smoothness(glcm_N))\n",
    "        array_aux.append(renglon_aux)\n",
    "    imagen_res = np.array(array_aux)\n",
    "    if mostrar:\n",
    "        plt.imshow(imagen_res)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return imagen_res\n",
    "\n",
    "# Recibe una imagen y un tamaño de ventana,\n",
    "# Calcula la contraste para cada ventana de la imagen\n",
    "# Regresa un arreglo en forma de imagen concatenando los resultados de cada ventana.\n",
    "def imagenWContrast(imagen,window_length,window_height,**kwargs):\n",
    "    Y, X = imagen.shape\n",
    "    array_aux = []\n",
    "    length_overlap = (kwargs[\"length_overlap\"] if (\"length_overlap\" in kwargs) else 0)\n",
    "    height_overlap = (kwargs[\"height_overlap\"] if (\"height_overlap\" in kwargs) else 0)\n",
    "    mostrar = (kwargs[\"show\"] if (\"show\" in kwargs) else False)\n",
    "    for texel_renglon in range(0,Y,window_height-height_overlap):\n",
    "        renglon_aux = []\n",
    "        for texel_startP in range(0,X,window_length-length_overlap):\n",
    "            ventana = imagen[texel_renglon:texel_renglon+window_height,texel_startP:texel_startP+window_length]\n",
    "            glcm_N = glcmMaker_h(ventana,True)\n",
    "            renglon_aux.append(contrast(glcm_N))\n",
    "        array_aux.append(renglon_aux)\n",
    "    imagen_res = np.array(array_aux)\n",
    "    if mostrar:\n",
    "        plt.imshow(imagen_res)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    return imagen_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mineral-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recibe una imagen y un tamaño de ventana\n",
    "# Calcula la entropia, homogeneidad, energia y contraste para cada ventana\n",
    "# Devuelve un unico arreglo concatenando los resultados\n",
    "def vectorizador(textura,window_l,window_h, **kwargs):\n",
    "    l_over = (kwargs[\"length_overlap\"] if (\"length_overlap\" in kwargs) else 0)\n",
    "    h_over = (kwargs[\"height_overlap\"] if (\"height_overlap\" in kwargs) else 0)\n",
    "    mostrar = (kwargs[\"show\"] if (\"show\" in kwargs) else False)\n",
    "    entropia = imagenWEntropy(textura,window_l,window_h,length_overlap=l_over,height_overlap=h_over,show=mostrar)\n",
    "    homogeneidad = imagenWHomogeneity(textura,window_l,window_h,length_overlap=l_over,height_overlap=h_over,show=mostrar)\n",
    "    smoothness = imagenWSmoothness(textura,window_l,window_h,length_overlap=l_over,height_overlap=h_over,show=mostrar)\n",
    "    contraste = imagenWContrast(textura,window_l,window_h,length_overlap=l_over,height_overlap=h_over,show=mostrar)\n",
    "    return np.dstack((entropia,homogeneidad,smoothness,contraste))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-emergency",
   "metadata": {},
   "source": [
    "### Transformación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "objective-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion recibe la \"imagen\" compuesta de caracteristicas y devuelve la lista de \"pixeles de caracteristicas\"\n",
    "def pixelsImage(imagen):\n",
    "    pixeles_clase = []\n",
    "    for renglon in imagen:\n",
    "        for pixel in renglon:\n",
    "            pixeles_clase.append(pixel)\n",
    "    return np.array(pixeles_clase)\n",
    "#vectCaractTx1 = pixelsImage(imagenC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "figured-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion auxiliar para mostrar el codigo de colores utilizado\n",
    "def mostrarColores(colores, **kwargs):\n",
    "    colormap = np.zeros((100,10,3), dtype=int)\n",
    "    texturemap = np.zeros((100,10,3), dtype=int)\n",
    "    fig, ax = plt.subplots()\n",
    "    for c in range(len(colores)):\n",
    "        colormap = np.concatenate((colormap,np.full((100,100,3), colores[c]),np.zeros((100,10,3), dtype=int)), axis=1)\n",
    "        ax.text(50+(110*c),50,'T'+str(c+1), style ='italic', fontsize = 15)\n",
    "        if (\"texturas\" in kwargs):\n",
    "            texturemap = np.concatenate((texturemap,np.dstack((kwargs['texturas'][c][0:100,0:100],kwargs['texturas'][c][0:100,0:100],kwargs['texturas'][c][0:100,0:100])),np.zeros((100,10,3), dtype=int)), axis=1)\n",
    "    if (\"texturas\" in kwargs):\n",
    "        colormap = np.concatenate((colormap, texturemap))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(colormap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-adventure",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Clasificación con Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-whale",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specialized-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta función recibe una lista de las matrices de cada clase\n",
    "def trainingBayess(matrices_clases):\n",
    "    # Entrenamiento\n",
    "    MUs = []\n",
    "    SIGMAs_inv = []\n",
    "    probas = []\n",
    "    ldDers = []\n",
    "    colores = []\n",
    "    for clase in matrices_clases:\n",
    "        MU = np.mean(clase, axis=0)\n",
    "        MUs.append(MU)\n",
    "        SIGMA = getSigma(clase)\n",
    "        SIGMA_inv = np.linalg.inv(SIGMA)\n",
    "        SIGMAs_inv.append(SIGMA_inv)\n",
    "        proba = probaClase(len(clase), clase.shape[0], clase.shape[1], len(matrices_clases))\n",
    "        probas.append(proba)\n",
    "        ldDer = ladoDerecho(np.linalg.det(SIGMA), proba)\n",
    "        ldDers.append(ldDer)\n",
    "        colores.append((np.random.rand(3)*1000%255).astype(int).tolist())\n",
    "    mostrarColores(colores)\n",
    "    return MUs, SIGMAs_inv, ldDers, colores\n",
    "#entrenamiento = trainingBayess([vectCaractTx1,vectCaractTx2,vectCaractTx3,vectCaractTx4,vectCaractTx5,vectCaractTx6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-apple",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Clasificación con knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recovered-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento para ajustar con la funcion de knn de scikitlearn\n",
    "def unificador(lista_vect, **kwargs):\n",
    "    vect_array = []\n",
    "    label_array = []\n",
    "    for n in range(len(lista_vect)):\n",
    "        for i in range(len(lista_vect[n])):\n",
    "            vect_array.append(lista_vect[n][i])\n",
    "            label_array.append( kwargs[\"labels\"][n] if (\"labels\" in kwargs) else (n+1))\n",
    "    return vect_array, label_array\n",
    "#samp_feat, samp_lab = unificador([vectCaractTx1,vectCaractTx2,vectCaractTx3,vectCaractTx4,vectCaractTx5,vectCaractTx6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-identifier",
   "metadata": {},
   "source": [
    "#### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dietary-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier()\n",
    "#model.fit(samp_feat,samp_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-submission",
   "metadata": {},
   "source": [
    "#### Transformación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "selected-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectIMG1 = pixelsImage(imgPC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-malaysia",
   "metadata": {},
   "source": [
    "#### Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "likely-single",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarKNN(clasificacion, forma, colores):\n",
    "    resultado = np.zeros((forma[0],forma[1],3), dtype=int)\n",
    "    aux = 0\n",
    "    for i in range(len(resultado)):\n",
    "        for j in range(len(resultado[i])):\n",
    "            resultado[i][j]= colores[clasificacion[aux]-1]\n",
    "            aux += 1\n",
    "    plt.imshow(resultado)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "absolute-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clasificacion1 = model.predict(vectIMG1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-better",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Parte B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "complicated-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(imagen):\n",
    "    gris = ((imagen[:,:,0]+imagen[:,:,1]+imagen[:,:,2])/3).astype(int)\n",
    "    return gris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-auditor",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "Al haber implementado un clasificador de Bayes para la clasificacion de 2 o mas imagenes nos dimos cuenta de que con la aplicacion directa de la regla de Bayes da como resultado una problema computacionalmente costoso que no hace mas que incrementarse conforme la cantidad de imagenes de entrenamiento y la complejidad aumenta. Por tanto, si bien es un buen punto de partida, no es un clasificador optimo. Ademas, aprendimos que es necesario tener un buen volumen de imagenes de entrenamiento y que para ponerlo a prueba exhaustivamente las imagenes de entrenamiento y prueba deben diferir.\n",
    "\n",
    "\n",
    "https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic\n",
    "https://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/\n",
    "\n",
    "### Referencias:\n",
    "\n",
    "- (s.a) (s.f) matplotlib.pyplot.plot Documentacion de Mat-plotlib. Consultado de https://matplotlib.org/stable/api/as7gen/matplotlib.pyplot.plot.html\n",
    "\n",
    "- (s.a) (s.f) matplotlib.contour.QuadContourSet Documentacion de Matplotlib. Consultado de https://matplotlib.org/stable/api/contourapi.html#matplotlib.contour.QuadContourSet\n",
    "\n",
    "- (s.a) (s.f) matplotlib.image.AxesImage Documentacion de Matplotlib. Consultado de https://matplotlib.org/stable/api/imageapi.html#matplotlib.image.AxesImage\n",
    "\n",
    "- (s.a) (s.f) matplotlib.pyplot.imshow Documentacion de Matplotlib. Consultado de https://matplotlib.org/stable/api/asgen/matplotlib.pyplot.imshow.html\n",
    "\n",
    "- (s.a) (s.f) matplotlib.patches.Patch. Documentacion de Matplotlib. Consultado de https://matplotlib.org/stable/api/asgen/matplotlib.patches.Patch.html\n",
    "\n",
    "- (s.a) (s.f) Shapely and geometric ob\u0002jects. Consultado de https://automating-gis\u0002processes.github.io/site/notebooks/L1/geometric-objects.html\n",
    "\n",
    "- (s.a) (s.f) matplotlib.path. Documentacion de Matplotlib. Consultado de https://matplotlib.org/stable/api/pathapi.html\n",
    "\n",
    "- (s.a) (s.f) matplotlib.pyplot.plot. Docu\u0002mentacion de Matplotlib. Consultado de https://matplotlib.org/stable/api/asgen/matplotlib.pyplot.plot.html\n",
    "\n",
    "- (s.a) (s.f) Image Resolution and DPI. Consultado de https://largeprinting.com/resources/image-resolution-and\u0002dpi.html\n",
    "\n",
    "- (s.a)(26 de dic, 2020) Apply a Gauss filter to an image with Python. Geeks for Geeks. Consultado de https://www.geeksforgeeks.org/apply-a-gauss-filter-to-an\u0002image-with-python/\n",
    "\n",
    "- (s.a) (14 de julio, 2019) Python PIL GaussianBlur() method. Geeks for Geeks. Consultado\n",
    "de https://www.geeksforgeeks.org/python-pil-gaussianblur\u0002method/\n",
    "\n",
    "- Banterla, D. (s/f) Texturas. Fac. In\u0002formatica San Sebastian. Consultado de http://www.ehu.eus/ccwintco/uploads/d/d7/Texturas.pdf\n",
    "\n",
    "- Dabbura, I. (17 de spetiembre, 2018) K-means Clustering: Algorithm, Applications, Evaluation Methods,and Drawbacks. Towards data science. Consultado de https://towardsdatascience.com/k-means-clustering\u0002algorithm-applications-evaluation-methods-and-drawbacks\u0002aa03e644b48a\n",
    "\n",
    "- gene (13 de abril, 2017) Geopandas Polygon to matplotlib patches Polygon conversion Stack Exchange. Consultado de https://gis.stackexchange.com/questions/197945/geopandas\u0002polygon-to-matplotlib-patches-polygon-conversion\n",
    "\n",
    "- gene (4 de junio, 2014). Converting Matplotlib con\u0002tour objects to Shapely objects. Stack Overflow. Consultado de https://gis.stackexchange.com/questions/99917/converting\u0002matplotlib-contour-objects-to-shapely-objects\n",
    "\n",
    "- Ghandi, R. (5 de Mayo, 2018) Naive Bayes Classifier Towards Data Science. Consultado de https://towardsdatascience.com/naive-bayes-classifier\u000281d512f50a7c\n",
    "\n",
    "- Gillies, S.(27 de sep, 2020) The Shapely User Manual. Shapely. Consultado de https://shapely.readthedocs.io/en/stable/manual.html\n",
    "\n",
    "- Hall-Beyer, M. (2017) GLCM Texture: A Tutorial v. 3.0. University of Calgary. Consultado de https://prism.ucalgary.ca/bitstream/handle/1880/51900/texture%20tutorial%20v%2030%20180206.pdf?sequence=11&isAllowed=y\n",
    "\n",
    "- jodag. (6 de mayo, 2020) Matplotlib -unable to save image in same resolution as original image. Stack Overflow. Consultado de https://stackoverflow.com/questions/34768717/matplotlib\u0002unable-to-save-image-in-same-resolution-as-original\u0002image34769840\n",
    "\n",
    "- Korstanje, J. (7 de abril, 2021) The k-Nearest Neigh\u0002bors (kNN) Algorithm in Python. RealPython. Consultado en https://realpython.com/knn-python/\n",
    "\n",
    "- Lin, W. et al. (2010) Image Segmentation Using the K\u0002means Algorithm for Texture Features. World Academy of Science, Engineering and Technology International Journal of Computer and Information Engineering\n",
    "\n",
    "- Navlani, A. (2 de agosto, 2018) KNN Classification using Scikit-learn. Datacamp. Consultado en https://www.datacamp.com/community/tutorials/k-nearest\u0002neighbor-classification-scikit-learn\n",
    "\n",
    "- R, Kirsten et al. (5 se septiembre, 2019) Performance of two multiscale texture algorithms in classifying silver gelatine paper via k-nearest neighbors. Open Archive Toulouse Archive Ouverte. Consultado de https://hal.archives-ouvertes.fr/hal\u000202279362/document\n",
    "\n",
    "- Rosebrock, A. (8 de agosto, 2016) k-NN classifier for image classification. pyImageSearch. Consultado en https://www.pyimagesearch.com/2016/08/08/k-nn-classifier\u0002for-image-classification/\n",
    "\n",
    "- tom10 (23 de Marzo, 2015) Python - convert contours to image. Stack Overflow. Consultado de https://stackoverflow.com/questions/29213238/python\u0002convert-contours-to-image2921417\n",
    "\n",
    "- A. Rosebrock, \"k-NN classifier for image classification - PyImageSearch\", PyImageSearch, 2021. [Online]. Available: https://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/. [Accessed: 26- Jul- 2021]. https://www.pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/\n",
    "\n",
    "- scikit-learn, \"sklearn.neighbors.KNeighborsClassifier — scikit-learn 0.24.2 documentation\", Scikit-learn.org. [Online]. Available: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.fit. [Accessed: 26- Jul- 2021]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
